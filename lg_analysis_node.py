import os
import json
import glob
from dotenv import load_dotenv
from google import genai
from google.genai import types

# â–¼ [ì¶”ê°€ë¨] ìš°ë¦¬ê°€ ë§Œë“  Stateì™€ PDF íŒŒì‹± ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
from state import GraphState
from document_parsing import extract_text_from_pdf 

load_dotenv()

# =========================================================
# [ì„¤ì •] íŒŒì¼ ê²½ë¡œ
# =========================================================
RFP_INPUT_DIR = os.path.join("data", "lang_graph")

# =========================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë‚´ìš©ì€ ê¸°ì¡´ê³¼ ë™ì¼í•©ë‹ˆë‹¤)
# =========================================================
SYSTEM_INSTRUCTION_ROUTER = """
ë„ˆëŠ” êµ­ê°€ R&D ì œì•ˆìš”ì²­ì„œ(RFP)ë¥¼ ë¶„ì„í•˜ì—¬ ì´ 8ê°œì˜ ì œì•ˆì„œ ì‘ì„± AI ì—ì´ì „íŠ¸ë“¤ì—ê²Œ ì—…ë¬´ë¥¼ ì •ë°€í•˜ê²Œ ë°°ë¶„í•˜ëŠ” 'PM(Project Manager) AI'ë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” RFP í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬, ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ì‘ë‹µí•´ë¼.
ë°˜ë“œì‹œ JSON í¬ë§·ì„ ì§€í‚¤ê³ , ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ì¡ë‹´ì€ í¬í•¨í•˜ì§€ ë§ˆë¼.

[ì‘ì—… ì§€ì¹¨]
ê° ì—ì´ì „íŠ¸(task)ì—ê²Œ í• ë‹¹í•  'relevant_context'ëŠ” ìš”ì•½í•˜ì§€ ë§ê³ , RFP ì›ë¬¸ì—ì„œ ê´€ë ¨ëœ ë¬¸ì¥ì´ë‚˜ ë‹¨ë½ì„ **ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ë°œì·Œ**í•´ì„œ ë„£ì–´ë¼. ì—ì´ì „íŠ¸ë“¤ì´ ì›ë¬¸ì„ ë³´ê³  íŒë‹¨í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

[ì¶œë ¥ JSON êµ¬ì¡°]
{
  "project_summary": {
    "title": "ê³µê³ ëª…",
    "purpose": "ê³¼ì œ ëª©í‘œ ìš”ì•½ (1~2ë¬¸ì¥)",
    "period": "ì´ ìˆ˜í–‰ ê¸°ê°„",
    "budget": "ì •ë¶€ì§€ì›ê¸ˆ ê·œëª¨",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]
  },
  "tasks": {
    "agency_intro": {
        "role": "ê¸°ê´€ ì†Œê°œ (1. ê¸°ê´€ ì†Œê°œ)",
        "instruction": "ì‹ ì²­ ìê²©, ìš°ëŒ€ ì‚¬í•­, ê°€ì  ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ê¸°ê´€ì˜ ì—­ëŸ‰ì„ ê°•ì¡°í•˜ëŠ” ì‘ì„± ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ì‹ ì²­ìê²©', 'ìš°ëŒ€ì‚¬í•­', 'ê°€ì ìš”ì¸', 'ì£¼ê´€ê¸°ê´€ ìš”ê±´' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "project_overview": {
        "role": "ì‚¬ì—… ê°œìš” (2. ì‚¬ì—… ê°œìš”)",
        "instruction": "ê³¼ì œì˜ ì •ì˜, ë¹„ì „, ìµœì¢… ëª©í‘œë¥¼ í¬ê´„ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ì‘ì„± ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ì‚¬ì—…ëª©ì ', 'ì§€ì›ë¶„ì•¼', 'ê³¼ì œ ê°œìš”' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "research_necessity": {
        "role": "ì—°êµ¬ í•„ìš”ì„± (3. ì—°êµ¬ í•„ìš”ì„±)",
        "instruction": "ê¸°ìˆ ì /ê²½ì œì /ì‚¬íšŒì  ì¤‘ìš”ì„±ê³¼ í˜„ì¬ì˜ ë¬¸ì œì (Pain Point)ì„ ë¶€ê°í•˜ëŠ” ì‘ì„± ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ì¶”ì§„ë°°ê²½', 'í•„ìš”ì„±', 'í˜„í™© ë° ë¬¸ì œì ', 'ì‹œì¥ ë™í–¥' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "research_goal": {
        "role": "ì—°êµ¬ ëª©í‘œ (4. ì—°êµ¬ ëª©í‘œ)",
        "instruction": "ìµœì¢… ëª©í‘œì™€ ì—°ì°¨ë³„ ëª©í‘œ, ì •ëŸ‰ì  ì„±ëŠ¥ì§€í‘œ(TP/KPI)ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ëŠ” ì‘ì„± ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ìµœì¢…ëª©í‘œ', 'ì„±ê³¼ì§€í‘œ', 'í‰ê°€í•­ëª©', 'TRL(ê¸°ìˆ ì„±ìˆ™ë„)' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "research_content": {
        "role": "ì—°êµ¬ ë‚´ìš© ë° ì‹œìŠ¤í…œ êµ¬ì¡° (5. ì—°êµ¬ ë‚´ìš©)",
        "instruction": "ì„¸ë¶€ ê°œë°œ ë‚´ìš©ê³¼ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜(êµ¬ì¡°ë„)ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ëŠ” ì‘ì„± ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ì—°êµ¬ë‚´ìš©', 'ê°œë°œë²”ìœ„', 'ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­', 'ì‹œìŠ¤í…œ êµ¬ì„±ë„ ìš”êµ¬ì‚¬í•­' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "promotion_plan": {
        "role": "ì¶”ì§„ ê³„íš (6. ì¶”ì§„ ê³„íš)",
        "instruction": "ê¸°ìˆ ê°œë°œ ì¶”ì§„ ì „ëµ, ì¶”ì§„ ì²´ê³„, ì¼ì •, ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì‘ì„± ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ì¶”ì§„ì „ëµ', 'ì¶”ì§„ì²´ê³„', 'ì¶”ì§„ì¼ì •', 'ì»¨ì†Œì‹œì—„ êµ¬ì„±' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "expected_outcome": {
        "role": "ê¸°ëŒ€ ì„±ê³¼ (7. ê¸°ëŒ€ ì„±ê³¼)",
        "instruction": "ê¸°ìˆ ì  íŒŒê¸‰íš¨ê³¼, ê²½ì œì  ë§¤ì¶œ ì¦ëŒ€ íš¨ê³¼, ì‚¬íšŒì  ê¸°ì—¬ë„ë¥¼ ì‘ì„±í•˜ëŠ” ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'ê¸°ëŒ€íš¨ê³¼', 'íŒŒê¸‰íš¨ê³¼' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    },
    "utilization_plan": {
        "role": "í™œìš© ê³„íš (8. í™œìš© ê³„íš)",
        "instruction": "ê°œë°œëœ ê¸°ìˆ ì˜ ì‚¬ì—…í™” ë°©ì•ˆ, íŒë¡œ ê°œì²™, í›„ì† ì—°êµ¬ ê³„íšì„ ì‘ì„±í•˜ëŠ” ì§€ì¹¨",
        "relevant_context": "RFP ë‚´ 'í™œìš©ë°©ì•ˆ', 'ì‚¬ì—…í™” ê³„íš', 'ì‹œì¥ ì§„ì… ì „ëµ' ê´€ë ¨ í…ìŠ¤íŠ¸ ë°œì·Œ"
    }
  }
}
"""

def get_latest_rfp_content() -> str:
    """data/lang í´ë”ì—ì„œ ìµœì‹  íŒŒì¼ì„ ì°¾ì•„ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    os.makedirs(RFP_INPUT_DIR, exist_ok=True)
    files = glob.glob(os.path.join(RFP_INPUT_DIR, "*"))
    
    if not files:
        raise FileNotFoundError(f"ì˜¤ë¥˜: '{RFP_INPUT_DIR}' í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    latest_file = max(files, key=os.path.getmtime)
    ext = os.path.splitext(latest_file)[1].lower()
    print(f"[PM ë…¸ë“œ] íŒŒì¼ ë¡œë“œ: {os.path.basename(latest_file)}")

    try:
        if ext == '.pdf':
            pdf_data_list = extract_text_from_pdf(latest_file)
            full_text = ""
            for page in pdf_data_list:
                full_text += f"\n--- Page {page['page_index'] + 1} ---\n" + "\n".join(page['texts']) + "\n"
            return full_text
        elif ext == '.json':
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return json.dumps(data, ensure_ascii=False) if not isinstance(data, list) else str(data)
        else:
            with open(latest_file, 'r', encoding='utf-8') as f:
                return f.read()
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"

# â–¼ [í•µì‹¬ ë³€ê²½] Stateë¥¼ ë°›ì•„ì„œ State í˜•ì‹ì„ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
def analyze_node(state: GraphState) -> dict:
    """
    [Node 1] RFP ë¶„ì„ ë…¸ë“œ
    ì…ë ¥: State (ë¹„ì–´ìˆê±°ë‚˜ rfp_textê°€ ì—†ì„ ìˆ˜ ìˆìŒ)
    ì¶œë ¥: State ì—…ë°ì´íŠ¸ (rfp_text ì±„ì›€, analyzed_json ì±„ì›€)
    """
    # 1. í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ stateì— ìˆìœ¼ë©´ ê·¸ê±° ì“°ê³ , ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ì½ê¸°)
    rfp_text = state.get("rfp_text")
    if not rfp_text:
        rfp_text = get_latest_rfp_content()
    
    # 2. Gemini í˜¸ì¶œ
    api_key = os.environ.get("GEMINI_API_KEY")
    client = genai.Client(api_key=api_key)
    
    print("[PM ë…¸ë“œ] ë¶„ì„ ì‹œì‘...")
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=f"ë‹¤ìŒ ì œì•ˆìš”ì²­ì„œ(RFP)ë¥¼ ë¶„ì„í•´ë¼:\n\n{rfp_text[:70000]}",
        config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION_ROUTER,
            response_mime_type="application/json", 
            temperature=0.1, 
        ),
    )

    try:
        result_json = json.loads(response.text)
        print("[PM ë…¸ë“œ] ë¶„ì„ ì™„ë£Œ. State ì—…ë°ì´íŠ¸í•¨.")
        
        # â˜… ì¤‘ìš”: ì „ì²´ Stateë¥¼ ë‹¤ ë¦¬í„´í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, "ë°”ë€ ë¶€ë¶„"ë§Œ ë¦¬í„´í•˜ë©´ ë©ë‹ˆë‹¤.
        return {
            "rfp_text": rfp_text,       # í…ìŠ¤íŠ¸ ì›ë³¸ ì €ì¥
            "analyzed_json": result_json # ë¶„ì„ ê²°ê³¼ ì €ì¥
        }
        
    except Exception as e:
        print(f"[ì˜¤ë¥˜] {e}")
        return {"analyzed_json": {"error": str(e)}}

# â–¼ [í…ŒìŠ¤íŠ¸ ì½”ë“œ ë³€ê²½] í˜¼ì ì‹¤í–‰í•  ë•Œë„ 'ê°€ì§œ State'ë¥¼ ë§Œë“¤ì–´ì„œ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    try:
        print("--- [TEST MODE] analyze_node ì‹¤í–‰ ---")
        
        # 1. ê°€ì§œ ë¹ˆ State ìƒì„±
        dummy_state = {"rfp_text": ""} 
        
        # 2. ë…¸ë“œ ì‹¤í–‰ (Stateê°€ ì—…ë°ì´íŠ¸ë˜ì–´ ëŒì•„ì˜´)
        result_update = analyze_node(dummy_state)
        
        # 3. ê²°ê³¼ í™•ì¸
        if "analyzed_json" in result_update:
            summary = result_update['analyzed_json'].get('project_summary', {})
            print("\n[ì„±ê³µ] ë¶„ì„ ê²°ê³¼ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤!")
            print(f"ğŸ“Œ ê³¼ì œëª…: {summary.get('title')}")
            print(f"ğŸ“Œ í‚¤ì›Œë“œ: {summary.get('keywords')}")
            
            # íŒŒì¼ë¡œë„ í•œë²ˆ ì €ì¥í•´ë³¼ê¹Œìš”? (í™•ì¸ìš©)
            with open("debug_analysis_result.json", "w", encoding="utf-8") as f:
                json.dump(result_update['analyzed_json'], f, indent=2, ensure_ascii=False)
            print(" -> ìƒì„¸ ë‚´ìš©ì€ 'debug_analysis_result.json'ì— ì €ì¥ë¨.")
        else:
            print("[ì‹¤íŒ¨] ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"[ì—ëŸ¬] {e}")