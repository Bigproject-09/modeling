import os
import json
import logging
import google.generativeai as genai
from pathlib import Path
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========================================================
# [ì„¤ì •] .env íŒŒì¼ ë¡œë“œ (ê²½ë¡œ ì•ˆì „ì¥ì¹˜ í¬í•¨)
# ========================================================
def load_api_key_robust():
    current_dir = Path(__file__).resolve().parent
    env_path = current_dir.parent / '.env'
    if env_path.exists():
        load_dotenv(dotenv_path=env_path)
        return os.getenv("GEMINI_API_KEY")
    load_dotenv()
    return os.getenv("GEMINI_API_KEY")

api_key = load_api_key_robust()

if not api_key:
    logger.error("[ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ 'GEMINI_API_KEY'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    genai.configure(api_key=api_key)

# ========================================================
# [ë‚´ë¶€ ìœ í‹¸] ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
# ========================================================
def _chunks_to_text(chunks):
    full_text = ""
    if isinstance(chunks, list):
        for chunk in chunks:
            # step1ì—ì„œ ë§Œë“  chunkëŠ” ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ë„, ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìŒ
            if isinstance(chunk, dict) and "text" in chunk:
                full_text += chunk["text"] + "\n\n"
            else:
                full_text += str(chunk) + "\n\n"
    else:
        full_text = str(chunks)
    
    # í† í° ì œí•œ ê³ ë ¤ (ì•½ 5ë§Œ ì)
    return full_text[:50000]

# ============================================================================
# [ê¸°ëŠ¥ 1] ìê²© ìš”ê±´ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Step 1 í˜¸ì¶œ ëŒ€ì‘)
# ============================================================================
def eligibility_checklist(chunks, source="") -> str:
    """
    Step 1ì—ì„œ eligibility_checklist(chunks=..., source=...) í˜•íƒœë¡œ í˜¸ì¶œí•¨.
    ë°˜í™˜ê°’: Markdown String
    """
    if not api_key: return "Error: No API Key"
    
    model = genai.GenerativeModel('gemini-1.5-flash')
    input_text = _chunks_to_text(chunks)
    
    # Step 1 ì½”ë“œì—ì„œ company_infoë¥¼ ì¸ìë¡œ ì•ˆ ë„˜ê²¨ì£¼ë¯€ë¡œ, ì—¬ê¸°ì„œ ì§ì ‘ ì½ì–´ì™€ì•¼ í•¨
    company_info_str = "ì •ë³´ ì—†ìŒ"
    try:
        current_dir = Path(__file__).resolve().parent
        company_path = current_dir.parent / "data" / "company" / "company_info.json"
        if company_path.exists():
            with open(company_path, "r", encoding="utf-8") as f:
                company_info_str = f.read()
    except:
        pass

    prompt = f"""
    ë‹¹ì‹ ì€ R&D ê³¼ì œ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì œê³µëœ ë¬¸ì„œ({source})ì—ì„œ **ì§€ì› ìê²©(Eligibility)**ê³¼ **í•„ìˆ˜ ìš”ê±´**ì„ ì¶”ì¶œí•˜ì—¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

    [ìš°ë¦¬ íšŒì‚¬ ì •ë³´]
    {company_info_str}

    [ì‘ì„± í˜•ì‹: Markdown]
    # ì§€ì› ìê²© ì²´í¬ë¦¬ìŠ¤íŠ¸ ({source})

    | êµ¬ë¶„ | í•„ìˆ˜ ìš”ê±´ ë‚´ìš© | ìš°ë¦¬ íšŒì‚¬ í˜„í™© | ì¶©ì¡± ì—¬ë¶€ (O/X/?) | ë¹„ê³  |
    |---|---|---|---|---|
    | (ì˜ˆ: ê¸°ì—…í˜•íƒœ) | (ì˜ˆ: ì¤‘ì†Œê¸°ì—…ë§Œ ê°€ëŠ¥) | ... | ... | ... |
    
    ## ğŸ’¡ ë³´ì™„ í•„ìš” ì‚¬í•­ ë° ì¡°ì–¸
    - (ì¶©ì¡±ë˜ì§€ ì•Šì€ í•­ëª©ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ì— ëŒ€í•´ ì¡°ì–¸)

    [ë¬¸ì„œ ë‚´ìš©]
    {input_text}
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"# ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨\nì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ============================================================================
# [ê¸°ëŠ¥ 2] ê³µê³ ë¬¸ ì‹¬ì¸µ ë¶„ì„ (Step 1 í˜¸ì¶œ ëŒ€ì‘)
# ============================================================================
def deep_analysis(chunks, source="") -> str:
    """
    Step 1ì—ì„œ deep_analysis(chunks=..., source=...) í˜•íƒœë¡œ í˜¸ì¶œí•¨.
    ë°˜í™˜ê°’: Markdown String
    """
    if not api_key: return "Error: No API Key"
    
    model = genai.GenerativeModel('gemini-1.5-flash')
    input_text = _chunks_to_text(chunks)

    prompt = f"""
    ë‹¹ì‹ ì€ ì •ë¶€ R&D ê³¼ì œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì œê³µëœ ë¬¸ì„œ({source})ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ**ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    [ì‘ì„± í˜•ì‹: Markdown]
    
    # ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼: {source}

    ## 1. ê³¼ì œ ê°œìš”
    - **ì‚¬ì—…ëª…/ê³¼ì œëª…**: 
    - **ìµœì¢… ëª©í‘œ**: (ëª…í™•í•˜ê²Œ 1ë¬¸ì¥)
    - **í•µì‹¬ ìš”ì•½**: (3ì¤„ ì´ë‚´)
    
    ## 2. ì£¼ìš” ì§€ì› ë‚´ìš©
    - **ê¸°ê°„**: 
    - **ì˜ˆì‚°(ì§€ì›ê¸ˆ)**:
    - **ì§€ì› ëŒ€ìƒ**:
    
    ## 3. í•µì‹¬ ìš”êµ¬ì‚¬í•­ (RFP ë¶„ì„)
    - (RFPë‚˜ ê³µê³ ì— ëª…ì‹œëœ ê¸°ìˆ ì /í–‰ì •ì  ìš”êµ¬ì‚¬í•­ì„ ìƒì„¸íˆ ê¸°ìˆ )
    
    ## 4. ì „ëµì  ì œì–¸
    - (ì„ ì • í™•ë¥ ì„ ë†’ì´ê¸° ìœ„í•œ ì „ëµ)

    [ë¬¸ì„œ ë‚´ìš©]
    {input_text}
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"# ë¶„ì„ ì‹¤íŒ¨\nì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ============================================================================
# [ê¸°ëŠ¥ 3] ìœ ì‚¬ ê³¼ì œ ê²€ìƒ‰ ìš”ì•½ (Step 2ìš© - ê¸°ì¡´ ìœ ì§€)
# ============================================================================
def summarize_report(json_data: dict) -> str:
    if not api_key: return "Error: No API Key"
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        track_a = json_data.get("track_a_same_ministry", [])
        track_b = json_data.get("track_b_diff_ministry", [])
        author = json_data.get("input_meta", {}).get("author", "ë¯¸ìƒ")

        prompt = f"""
        ë‹¹ì‹ ì€ ì •ë¶€ R&D ê³¼ì œ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ì‹ ê·œ ê³µê³ (ì†Œê´€: {author})ì™€ ìœ ì‚¬í•œ ê³¼ê±° ê³¼ì œë“¤ì„ ë¶„ì„í•˜ì—¬ **í•µì‹¬ ìš”ì•½ ë³´ê³ ì„œ**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

        [Track A: ì¤‘ë³µì„± ê²€í†  (ë™ì¼ ë¶€ì²˜)]
        {json.dumps(track_a, ensure_ascii=False)}

        [Track B: ë²¤ì¹˜ë§ˆí‚¹ (íƒ€ ë¶€ì²˜)]
        {json.dumps(track_b, ensure_ascii=False)}

        [ì‘ì„± ì§€ì¹¨]
        1. Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±: | ì—°ë„ | ë¶€ì²˜ | ê³¼ì œëª… | ìœ ì‚¬ë„ | í•µì‹¬ ìš”ì•½(30ì) |
        2. ì¢…í•© ì˜ê²¬ 3ì¤„ ì‘ì„±.
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"[ì˜¤ë¥˜] {str(e)}"


# ============================================================================
# [ê¸°ëŠ¥ 4] ëŒ€ë³¸ ìƒì„± (Step 4ìš© - ê¸°ì¡´ ìœ ì§€)
# ============================================================================
def generate_script_and_qna(ppt_text: str) -> dict:
    if not api_key: return None
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"""
        R&D ê³¼ì œ ë°œí‘œë¥¼ ìœ„í•œ ëŒ€ë³¸ê³¼ Q&Aë¥¼ JSONìœ¼ë¡œ ìƒì„±í•´.
        [JSON êµ¬ì¡°] {{ "slides": [{{ "page": 1, "script": "..." }}], "qna": [...] }}
        [PPT ë‚´ìš©] {ppt_text}
        """
        response = model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```"): text = text.split("```json")[1].split("```")[0].strip()
        elif text.startswith("json"): text = text.replace("json", "", 1).strip()
        return json.loads(text)
    except Exception as e:
        logger.error(f"[ì˜¤ë¥˜] ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None