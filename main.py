# main.py
import os
import uuid
import json
from fastapi import FastAPI, UploadFile, File, Query
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
import tempfile

load_dotenv()

from document_api import ingest_to_db, API_KEY
from parsing import parse_file_to_json

# ì„¹ì…˜ ëª¨ë“œìš© ìœ í‹¸ (ì´ë¯¸ í”„ë¡œì íŠ¸ì— ìˆëŠ” ê±¸ ì‚¬ìš©)
from utils.document_parsing import parse_docx_to_blocks, extract_text_from_pdf
from utils.section import SectionSplitter

app = FastAPI()


# =========================
# ê¸°ì—…ë§ˆë‹¹ ê³µê³  ìˆ˜ì§‘
# =========================
@app.post("/collect/notices")
def collect_notices():
    """
    ê¸°ì—…ë§ˆë‹¹ ê¸°ìˆ ê³µê³  ìˆ˜ì§‘
    - document_api.ingest_to_db() í˜¸ì¶œ
    - project_notices, notice_files, notice_hashtags í…Œì´ë¸”ì— ì €ì¥
    """
    print("ğŸ”¥ COLLECT CALLED")
    inserted = ingest_to_db(API_KEY)
    print(f"ğŸ”¥ COLLECT DONE: {inserted}ê±´ ìˆ˜ì§‘")
    return {"inserted": inserted}


# =========================
# íŒŒì¼ íŒŒì‹± (DB ì €ì¥ì€ Springì—ì„œ + mode ì˜µì…˜ ì¶”ê°€)
# =========================
@app.post("/parse")
async def parse_notice(file: UploadFile = File(...),
                       mode: str = Query(default="notice", description="notice|sections")):
    """
    íŒŒì¼ íŒŒì‹±ë§Œ ìˆ˜í–‰ (DB ì €ì¥ì€ Spring Bootì—ì„œ ì²˜ë¦¬)
    
    mode=notice (ê¸°ë³¸): ê¸°ì¡´ ê³µê³  íŒŒì‹± ê·¸ëŒ€ë¡œ parse_file_to_json() ê²°ê³¼ ë°˜í™˜
    mode=sections        : ì‚¬ì—…ë³´ê³ ì„œ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸(list[dict]) ë°˜í™˜

    Flow:
    1. Spring Boot: NoticeFile ìƒì„± + NoticeAttachment ìƒì„± (WAIT ìƒíƒœ)
    2. Spring Boot â†’ FastAPI: íŒŒì¼ ì „ì†¡
    3. FastAPI: íŒŒì‹± ìˆ˜í–‰ í›„ ê²°ê³¼ JSON ë°˜í™˜ â† ì´ í•¨ìˆ˜
    4. Spring Boot: NoticeAttachment.markDone(parsedJson) í˜¸ì¶œ
    """
    print(f"ğŸ”¥ PARSE CALLED: {file.filename}")

    os.makedirs("tmp", exist_ok=True)
    ext = os.path.splitext(file.filename)[1].lower()
    tmp_path = os.path.join("tmp", f"{uuid.uuid4().hex}{ext}")

    try:
        # 1) ì„ì‹œ ì €ì¥
        content = await file.read()
        with open(tmp_path, "wb") as f:
            f.write(content)

        # 2) modeì— ë”°ë¼ íŒŒì‹±
        if mode == "notice":
            parsed = parse_file_to_json(tmp_path)
            print(f"PARSE SUCCESS (notice): {file.filename}")
            return JSONResponse(content=parsed, status_code=200)

        elif mode == "sections":
            sections = _parse_to_sections(tmp_path, ext)
            print(f"PARSE SUCCESS (sections): {file.filename} / sections={len(sections)}")
            return JSONResponse(content=sections, status_code=200)

        else:
            return JSONResponse(
                status_code=400,
                content={"error": f"invalid mode: {mode} (allowed: notice|sections)"}
            )

    except Exception as e:
        print(f"âŒ PARSE FAILED: {file.filename} - {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)

def _parse_to_sections(path: str, ext: str) -> list[dict]:
    """
    parse_file_to_json() ê²°ê³¼ë¥¼ SectionSplitterê°€ ê¸°ëŒ€í•˜ëŠ”
    [ {page_index:int, texts:list[str]}, ... ] í˜•íƒœë¡œ ì •ê·œí™”í•œ ë’¤,
    ëª©ì°¨ ê¸°ë°˜ ì„¹ì…˜ ë¶„ë¦¬ ê²°ê³¼ë¥¼ list[dict]ë¡œ ë°˜í™˜
    """
    # 1) ê¸°ì¡´ íŒŒì„œë¡œ JSON ë§Œë“¤ê¸°
    parsed_json = parse_file_to_json(path)

    # 2) SectionSplitter ì…ë ¥ í¬ë§·ìœ¼ë¡œ ì •ê·œí™”
    pages = _normalize_parsed_json_for_splitter(parsed_json)

    # 3) ì„ì‹œ json íŒŒì¼ ìƒì„± (SectionSplitterëŠ” json_pathë¥¼ ë°›ìŒ)
    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False, encoding="utf-8") as tf:
        json.dump(pages, tf, ensure_ascii=False)
        tmp_json_path = tf.name

    try:
        splitter = SectionSplitter(json_path=tmp_json_path)

        # section.py ê¸°ì¤€: split_into_sections()ê°€ ì •ë‹µ
        sections = splitter.split_into_sections()

        # dataclass -> dict ì •ê·œí™”
        normalized = []
        for s in sections:
            if isinstance(s, dict):
                normalized.append(s)
            elif hasattr(s, "to_dict"):
                normalized.append(s.to_dict())
            else:
                normalized.append(s.__dict__)
        return normalized

    finally:
        if tmp_json_path and os.path.exists(tmp_json_path):
            os.remove(tmp_json_path)

def _normalize_parsed_json_for_splitter(parsed_json) -> list[dict]:
    """
    parse_file_to_json()ì˜ ì¶œë ¥ì´ ë¬´ì—‡ì´ë“ ,
    SectionSplitterê°€ ìš”êµ¬í•˜ëŠ” list[dict(page_index, texts)]ë¡œ ë§ì¶˜ë‹¤.
    """
    # ì¼€ì´ìŠ¤1) ì´ë¯¸ listë¼ë©´ ê·¸ëŒ€ë¡œ í›„ë³´
    data = parsed_json

    # ì¼€ì´ìŠ¤2) dictë¼ë©´ í”í•œ í‚¤ë“¤ì—ì„œ pagesë¥¼ êº¼ë‚´ê¸°
    if isinstance(parsed_json, dict):
        for k in ["pages", "page_list", "data", "results"]:
            if k in parsed_json and isinstance(parsed_json[k], list):
                data = parsed_json[k]
                break

    # ê·¸ë˜ë„ listê°€ ì•„ë‹ˆë©´ ì‹¤íŒ¨
    if not isinstance(data, list):
        raise RuntimeError(f"parse_file_to_json ê²°ê³¼ê°€ listê°€ ì•„ë‹˜. type={type(parsed_json)} keys={list(parsed_json.keys()) if isinstance(parsed_json, dict) else None}")

    normalized_pages: list[dict] = []
    for i, p in enumerate(data):
        # pê°€ dictê°€ ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ë¡œ ì·¨ê¸‰
        if not isinstance(p, dict):
            normalized_pages.append({"page_index": i, "texts": [str(p)]})
            continue

        # page index í›„ë³´ë“¤
        page_index = (
            p.get("page_index")
            if p.get("page_index") is not None else
            p.get("page")
            if p.get("page") is not None else
            p.get("page_no")
            if p.get("page_no") is not None else
            p.get("pageNumber")
            if p.get("pageNumber") is not None else
            i
        )

        # texts í›„ë³´ë“¤
        texts = None

        if isinstance(p.get("texts"), list):
            texts = p["texts"]

        elif isinstance(p.get("contents"), list):
            texts = [str(x) for x in p["contents"] if str(x).strip()]

        elif isinstance(p.get("text"), str):
            # í•œ ë©ì–´ë¦¬ í…ìŠ¤íŠ¸ë©´ ì¤„ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ listë¡œ
            texts = [line for line in p["text"].splitlines() if line.strip()]

        elif isinstance(p.get("lines"), list):
            texts = [str(x) for x in p["lines"] if str(x).strip()]

        elif isinstance(p.get("blocks"), list):
            # blocks = [{"text": "..."}...] ê°™ì€ í˜•íƒœ ëŒ€ì‘
            tmp = []
            for b in p["blocks"]:
                if isinstance(b, dict) and b.get("text"):
                    tmp.append(str(b["text"]))
                elif isinstance(b, str):
                    tmp.append(b)
            texts = [t for t in tmp if t.strip()]

        elif isinstance(p.get("content"), list):
            texts = [str(x) for x in p["content"] if str(x).strip()]

        else:
            # ìµœí›„: dict ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ
            texts = [json.dumps(p, ensure_ascii=False)]

        normalized_pages.append({
            "page_index": int(page_index) if str(page_index).isdigit() else i,
            "texts": texts
        })

    return normalized_pages

# =========================
# í—¬ìŠ¤ì²´í¬
# =========================
@app.get("/health")
def health_check():
    return {"status": "ok", "message": "FastAPI is running"}

# =========================
# íŒŒì‹± ìƒíƒœ ì¡°íšŒ (ì„ íƒì‚¬í•­)
# =========================
@app.get("/parse/formats")
def supported_formats():
    """
    ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ ì¡°íšŒ
    """
    return {
        "supported_formats": [".pdf", ".docx"],
        "max_file_size_mb": 50
    }

# ===== ë¶„ì„ API =====
from pydantic import BaseModel

class Step1Request(BaseModel):
    notice_id: int
    company_id: int = 1

@app.post("/api/analyze/step1")
def api_run_step1(req: Step1Request):
    from features.rfp_analysis_checklist.main_notice import run_notice_step1
    print("RAW REQ:", req.model_dump())
    print(f"[Step 1] ë¶„ì„ ìš”ì²­: notice_id={req.notice_id}, company_id={req.company_id}")
    result = run_notice_step1(notice_id=req.notice_id, company_id=req.company_id)
    return {"status": "success", "data": result}

class NoticeOnlyRequest(BaseModel):
    notice_id: int

@app.post("/api/analyze/step2")
def api_run_step2(req: NoticeOnlyRequest):
    from features.rnd_search.main_search import main as run_search
    print(f"[Step 2] ìœ ì‚¬ RFP ê²€ìƒ‰ ìš”ì²­: notice_id={req.notice_id}")
    result = run_search(notice_id=req.notice_id)
    return {"status": "success", "data": result}

@app.post("/api/analyze/step3")
def api_run_step3(req: NoticeOnlyRequest):
    # Step3ëŠ” í˜¸ì¶œë  ë•Œë§Œ import â†’ nodes_code ì—†ì–´ë„ Step1 ì„œë²„ëŠ” ëœ¸
    from features.ppt_maker.main_ppt import main as run_ppt_maker
    print(f"[Step 3] PPT ìƒì„± ìš”ì²­: notice_id={req.notice_id}")
    try:
        result = run_ppt_maker(notice_id=req.notice_id)
    except TypeError:
        result = run_ppt_maker()
    return {"status": "success", "data": result}

@app.post("/api/analyze/step4")
def api_run_step4(req: NoticeOnlyRequest):
    from features.ppt_script.main_script import main as run_script_gen
    print(f"[Step 4] ëŒ€ë³¸ ìƒì„± ìš”ì²­: notice_id={req.notice_id}")
    try:
        result = run_script_gen(notice_id=req.notice_id)
    except TypeError:
        result = run_script_gen()
    return {"status": "success", "data": result}

if __name__ == "__main__":
    import uvicorn
    # host="0.0.0.0"ì€ ì™¸ë¶€ ì ‘ì† í—ˆìš©, reload=TrueëŠ” ì½”ë“œ ìˆ˜ì • ì‹œ ìë™ ì¬ì‹œì‘
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)