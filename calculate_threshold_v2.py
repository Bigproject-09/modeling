import os
import sys
import glob
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from dotenv import load_dotenv

# 1. [ê²½ë¡œ ì„¤ì •]
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

try:
    from utils.document_parsing import extract_text_from_pdf, parse_docx_to_blocks
    from utils.vector_db import search_two_tracks
except ImportError:
    print("âŒ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

load_dotenv()

# ==========================================================
# [ì„¤ì •] í…ŒìŠ¤íŠ¸í•  ë¬¸ì„œ í´ë”
TEST_DATA_DIR = r"C:\Users\User\Downloads\df"
# ==========================================================

CACHE_FILE = os.path.join(current_dir, "full_dist_cache.json")

def set_korean_font():
    sns.set_theme(style="whitegrid")
    font_path = 'C:/Windows/Fonts/malgun.ttf'
    if os.path.exists(font_path):
        font_prop = fm.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = font_prop.get_name()
    else:
        plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False

def collect_full_scores(folder_path):
    if os.path.exists(CACHE_FILE):
        print(f"\n[âš¡] ìºì‹œ ë°ì´í„° ë¡œë“œ: {CACHE_FILE}")
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)

    files = glob.glob(os.path.join(folder_path, "*.pdf")) + glob.glob(os.path.join(folder_path, "*.docx"))
    
    if not files:
        print(f"[!] í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        return []

    print(f"\n[*] ì´ {len(files)}ê°œ íŒŒì¼ë¡œ 'DB ì „ì²´ ì™„ì „ ê²€ìƒ‰' ì‹œì‘...")
    print("    (ì œí•œ ì—†ì´ ê²€ìƒ‰ ê°€ëŠ¥í•œ ëª¨ë“  ìœ ì‚¬ ë¬¸ì„œë¥¼ ê¸ì–´ì˜µë‹ˆë‹¤. ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
    
    all_scores = []
    
    for i, file_path in enumerate(files):
        print(f"[{i+1}/{len(files)}] ì „ì²´ ë°ì´í„° ìŠ¤ìº” ì¤‘: {os.path.basename(file_path)}")
        
        full_text = ""
        try:
            if file_path.endswith(".pdf"):
                parsed = extract_text_from_pdf(file_path)
                for page in parsed: full_text += " ".join(page.get("texts", [])) + "\n"
            elif file_path.endswith(".docx"):
                parsed = parse_docx_to_blocks(file_path)
                full_text = str(parsed)
        except Exception:
            continue
            
        if len(full_text.strip()) < 50: continue

        try:
            # ğŸ”¥ [í•µì‹¬] top_kë¥¼ 5000ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ì‹¤ìƒ DB ì „ì²´ë¥¼ ê°€ì ¸ì˜´
            # ë¶€ì²˜ëª… "ALL_SCAN"ìœ¼ë¡œ í•„í„°ë§ ë¬´ë ¥í™” -> ì „ì²´ ê²€ìƒ‰
            results = search_two_tracks(
                notice_text=full_text,
                ministry_name="ALL_SCAN", 
                top_k_a=0, 
                top_k_b=5000, # <--- 50ê°œê°€ ì•„ë‹ˆë¼ 5000ê°œ! (ì „ë¶€ ë‹¤)
                score_threshold=0.0
            )
            
            # í•„í„°ë§ ì—†ì´ ëª½ë•… ìˆ˜ì§‘
            items = results.get('track_b', [])
            for item in items:
                all_scores.append(item['score'])

        except Exception as e:
            print(f"  - ì—ëŸ¬: {e}")

    if all_scores:
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(all_scores, f)
        print(f"\n[ğŸ’¾] ì „ì²´ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {CACHE_FILE}")

    return all_scores

def show_full_statistics(scores):
    if not scores:
        print("[!] ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    scores = np.array(scores)
    mean_val = np.mean(scores)
    median_val = np.median(scores)
    
    print("\n" + "="*70)
    print(f" ğŸ“Š [DB ì „ì²´ ì™„ì „ ë¶„ì„ ê²°ê³¼]")
    print("="*70)
    print(f" â€¢ ìˆ˜ì§‘ëœ ì´ ìœ ì‚¬ë„ ë°ì´í„° ìˆ˜ : {len(scores)} ê°œ")
    print(f" â€¢ ì „ì²´ í‰ê·  ì ìˆ˜           : {mean_val:.2f} ì ")
    print(f" â€¢ ì¤‘ì•™ê°’ (Median)          : {median_val:.2f} ì ")
    print("-" * 70)
    print(" ğŸ’¡ ê²°ë¡  (ì´ ì ìˆ˜ë¥¼ ì“°ì„¸ìš”)")
    print(f"   ğŸ‘‰ [í‰ê·  ê¸°ì¤€] Score Threshold : {mean_val:.1f}")
    print(f"   ğŸ‘‰ [ì¤‘ì•™ ê¸°ì¤€] Score Threshold : {median_val:.1f}")
    print("="*70)

    # ê·¸ë˜í”„
    plt.figure(figsize=(12, 6))
    sns.histplot(scores, kde=True, bins=100, color='black') # êµ¬ê°„ì„ 100ê°œë¡œ ìª¼ê°œì„œ ìƒì„¸í•˜ê²Œ ë´„
    plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean ({mean_val:.1f})')
    plt.axvline(median_val, color='yellow', linestyle=':', linewidth=2, label=f'Median ({median_val:.1f})')
    
    plt.title(f'Full Database Similarity Distribution (Top-5000 Limit)')
    plt.xlabel('Similarity Score')
    plt.ylabel('Count')
    plt.legend()
    
    save_path = os.path.join(current_dir, "full_distribution.png")
    plt.savefig(save_path)
    print(f" [Graph] ì „ì²´ ë¶„í¬ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")

if __name__ == "__main__":
    set_korean_font()
    scores = collect_full_scores(TEST_DATA_DIR)
    show_full_statistics(scores)